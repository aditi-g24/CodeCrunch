# Offroad Semantic Segmentation - Competition Solution

**High-performance semantic segmentation for Duality AI's Offroad Hackathon**

Optimized for maximum IoU and strong generalization to unseen desert environments.

## ğŸ¯ Features

### Architecture
- **SegFormer** (default) - Transformer-based encoder with superior generalization
  - Hierarchical MiT (Mix Transformer) backbone
  - Better global context understanding
  - More robust to domain shift than pure CNNs
- **DeepLabV3+** (alternative) - Strong CNN baseline with ASPP

### Training Strategy
- **Hybrid Loss**: 0.5 Ã— CrossEntropy + 0.5 Ã— Dice Loss
- **Class Weights**: Automatically computed from pixel frequency
- **Mixed Precision**: FP16 training for faster convergence
- **Strong Augmentation**: Optimized for desert domain generalization
  - Random rotation, scaling, flipping
  - Color jitter, gamma, tone curves
  - Gaussian noise and blur
  - Random shadows
- **Learning Rate Scheduling**: CosineAnnealing or ReduceLROnPlateau
- **Early Stopping**: Prevents overfitting

### Evaluation
- Per-class IoU
- Mean IoU
- Pixel Accuracy
- Precision & Recall per class
- Confusion Matrix
- Test-Time Augmentation (TTA)

## ğŸ“ Project Structure

```
offroad_segmentation/
â”œâ”€â”€ config.py           # All hyperparameters and settings
â”œâ”€â”€ dataset.py          # Data loading and augmentation
â”œâ”€â”€ loss.py            # Hybrid loss function
â”œâ”€â”€ metrics.py         # Comprehensive evaluation metrics
â”œâ”€â”€ model.py           # Model architectures
â”œâ”€â”€ train.py           # Training script
â”œâ”€â”€ test.py            # Inference script
â”œâ”€â”€ requirements.txt   # Dependencies
â””â”€â”€ README.md          # This file

data/                  # Your data directory
â”œâ”€â”€ Train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â”œâ”€â”€ Val/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â””â”€â”€ testImages/

runs/                  # Generated outputs
â”œâ”€â”€ checkpoints/       # Model checkpoints
â”œâ”€â”€ logs/             # Training logs and plots
â””â”€â”€ predictions/      # Test predictions
```

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Create conda environment
conda create -n offroad python=3.9
conda activate offroad

# Install dependencies
pip install -r requirements.txt
```

### 2. Prepare Data

Update paths in `config.py`:
```python
DATA_ROOT = Path("./data")  # Point to your data directory
```

Expected structure:
```
data/
â”œâ”€â”€ Train/
â”‚   â”œâ”€â”€ images/  # Training images
â”‚   â””â”€â”€ masks/   # Training masks
â”œâ”€â”€ Val/
â”‚   â”œâ”€â”€ images/  # Validation images
â”‚   â””â”€â”€ masks/   # Validation masks
â””â”€â”€ testImages/  # Test images (NO masks)
```

### 3. Configure Model

Edit `config.py` to select architecture:

```python
# For SegFormer (recommended)
MODEL_NAME = "segformer"
ENCODER_NAME = "mit_b3"  # Options: mit_b0, mit_b1, mit_b2, mit_b3, mit_b4, mit_b5

# For DeepLabV3+
MODEL_NAME = "deeplabv3plus"
ENCODER_NAME = "resnet101"  # Options: resnet50, resnet101
```

### 4. Train

```bash
python train.py
```

**Training outputs:**
- `runs/checkpoints/best_model.pth` - Best model based on validation IoU
- `runs/logs/training_history.png` - Training curves
- `runs/logs/confusion_matrix_best.png` - Confusion matrix
- `runs/logs/training_history.json` - Metrics history

### 5. Test/Inference

```bash
# Run inference on test set
python test.py

# Evaluate on validation set
python test.py --eval
```

**Test outputs:**
- `runs/predictions/pred_*.png` - Predicted segmentation masks
- `runs/predictions/vis_*.png` - Visualizations (original + prediction overlay)
- `runs/predictions/color_legend.png` - Class color mapping

## âš™ï¸ Configuration

Key hyperparameters in `config.py`:

```python
# Model
MODEL_NAME = "segformer"  # or "deeplabv3plus"
NUM_CLASSES = 11

# Training
BATCH_SIZE = 8
NUM_EPOCHS = 150
LEARNING_RATE = 1e-4
WEIGHT_DECAY = 1e-4

# Loss
CE_WEIGHT = 0.5
DICE_WEIGHT = 0.5

# Augmentation
AUG_PROB = 0.8
ROTATION_LIMIT = 15
BRIGHTNESS_LIMIT = 0.2
CONTRAST_LIMIT = 0.2

# Optimization
SCHEDULER = "cosine"  # or "plateau"
EARLY_STOPPING_PATIENCE = 25

# Test-Time Augmentation
USE_TTA = True
```

## ğŸ“ Training Tips

### For Better Generalization
1. **Strong augmentation is critical** - Desert scenes vary in lighting, color
2. **Don't overtrain** - Use early stopping, monitor validation IoU
3. **Class weights help** - Desert classes are often imbalanced
4. **TTA improves results** - Especially horizontal flip for symmetry

### For Faster Training
1. Reduce `BATCH_SIZE` if GPU memory limited
2. Use smaller encoder: `mit_b0` or `mit_b1`
3. Reduce `IMAGE_HEIGHT` and `IMAGE_WIDTH`
4. Disable `USE_AMP` if causing issues

### For Higher Accuracy
1. Use larger encoder: `mit_b4` or `mit_b5`
2. Increase training epochs
3. Enable TTA during validation
4. Fine-tune augmentation parameters

## ğŸ“Š Expected Performance

**On similar desert segmentation tasks:**
- Mean IoU: 0.70 - 0.85 (depending on domain shift)
- Pixel Accuracy: 0.85 - 0.95
- Training time: 2-4 hours on RTX 3090 (150 epochs)

## ğŸ”§ Troubleshooting

**Out of Memory:**
```python
# In config.py
BATCH_SIZE = 4  # Reduce batch size
IMAGE_HEIGHT = 384  # Reduce image size
IMAGE_WIDTH = 384
```

**Poor validation performance:**
- Check class distribution - may need stronger weights
- Increase augmentation strength
- Reduce learning rate
- Try different encoder

**Model not loading:**
- Check `NUM_CLASSES` matches your data
- Verify checkpoint path exists
- Ensure model architecture matches checkpoint

## ğŸ“ Submission

For competition submission:
1. Run inference: `python test.py`
2. Submit masks from: `runs/predictions/pred_*.png`
3. Include best model: `runs/checkpoints/best_model.pth`
4. Document mean IoU from validation

## ğŸ† Why This Solution Wins

1. **SegFormer Architecture**: Superior generalization over CNNs
2. **Hybrid Loss**: Combines pixel accuracy + region overlap
3. **Domain-Aware Augmentation**: Simulates lighting/color variations
4. **Automatic Class Balancing**: Handles imbalanced desert classes
5. **TTA**: 1-2% IoU boost at inference time
6. **Production Ready**: Clean, modular, reproducible code

## ğŸ“š References

- SegFormer: [Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)
- DeepLabV3+: [Encoder-Decoder with Atrous Separable Convolution](https://arxiv.org/abs/1802.02611)
- Segmentation Models PyTorch: [GitHub](https://github.com/qubvel/segmentation_models.pytorch)

## ğŸ“§ Support

For issues or questions:
1. Check configuration in `config.py`
2. Review error messages in console
3. Verify data structure matches expected format
4. Check GPU memory and dependencies

Good luck with the competition! ğŸš€
